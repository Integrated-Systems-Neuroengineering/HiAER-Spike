[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to HiAER-Spike v0.1.0",
    "section": "",
    "text": "Welcome to HiAER-Spike v0.1.0\nHiAER-Spike (Hierarchical Address-Event Routing of spikes) is a python library designed to interact with the ISN CRI project hosted on the San Diego Supercomputer (SDSC). The goal of this project is to streamline access to large-scale simulations of spiking neural networks for the research community. It primarily targets researchers with a focus on neuromorphic computing within the fields of artificial intelligence and neuroscience. With HiAER-Spike, a user can design a spiking neural network and run it using one of two backends:\n\nthe CRI neuromorphic hardware or\na python simulation of the hardware"
  },
  {
    "objectID": "menu/api/overview.html",
    "href": "menu/api/overview.html",
    "title": "Overview",
    "section": "",
    "text": "hs_api is a python library for interacting with the ISN CRI project hosted at SDSC. This project aims to make massive scale simulations of spiking neural networks easily accessible to the research community, and in particular researchers interested in neuromorphic computing for artificial intelligence and neuroscience. This library allows a user to define a spiking neural network and execute it on one of two backends:\n\nthe CRI neuromorphic hardware or\na python simulation of the hardware\n\nCheck out the Usage section for further information."
  },
  {
    "objectID": "menu/api/overview.html#introduction",
    "href": "menu/api/overview.html#introduction",
    "title": "Overview",
    "section": "",
    "text": "hs_api is a python library for interacting with the ISN CRI project hosted at SDSC. This project aims to make massive scale simulations of spiking neural networks easily accessible to the research community, and in particular researchers interested in neuromorphic computing for artificial intelligence and neuroscience. This library allows a user to define a spiking neural network and execute it on one of two backends:\n\nthe CRI neuromorphic hardware or\na python simulation of the hardware\n\nCheck out the Usage section for further information."
  },
  {
    "objectID": "menu/api/overview.html#installation",
    "href": "menu/api/overview.html#installation",
    "title": "Overview",
    "section": "Installation",
    "text": "Installation\n\nSimple Installation\n$ pip install hs_api\n\n\nDevelopment Installation\n\nFirst install Poetry\n\nIf Poetry doesn’t install it may be necessary to install an alternative Python distribution such as Conda\n\nClone the following dependencies and the hs_api repo:\n\n# Dependencies\n$ git clone https://github.com/Integrated-Systems-Neuroengineering/connectome_utils.git\n$ git clone  https://github.com/Integrated-Systems-Neuroengineering/hs_bridge.git\n\n# API repo\n$ git clone https://github.com/Integrated-Systems-Neuroengineering/hs_api.git\n\ncd into the hs_api repo you cloned and install the needed dependencies. Resolving dependencies may take a while.\n\n$ cd hs_api\n$ poetry install\n\nFinally activate the development environment\n\n$ poetry shell"
  },
  {
    "objectID": "menu/api/submitting-jobs.html",
    "href": "menu/api/submitting-jobs.html",
    "title": "HiAER-Spike",
    "section": "",
    "text": "The same Python scripts you’ve developed and run on your local machine can be deployed to the CRI servers to run on the actual CRI hardware. Just make sure all the libraries you import in your script are available on the CRI servers. The CRI hardware is hosted in the San Diego Supercomputing Center and jobs may be submitted to run on the hardware via the Neuroscience Gateway. First you must register an account with Neuroscience Gateway in order to submit jobs. Perform the following steps to submit a task to NSG\n\nPut your CRI Python script in a folder of any name, then zip the folder\nLog into NSG.\n\n\n\nCreate a task folder if there is none listed on the upper left. It’s a place to hold related jobs.\n\n\n\nClick on data, and save the previously created zip file as the data. Here ‘data’ is ambiguous - it is the job and its data.\nClick on task.\nCreate a new task if needed (or clone an old one).\nAssign the zip you just uploaded as data as the input to the task.\nSelect Python for CRI as the software to run.\nSet parameters for the task:\n\nSet execution ‘wall time’, cores, and GB of DRAM if you wish. Please be consideret to others and only request the hardware you need.\nEnter the name of your.py python scrip as the “input” using the same name as is in the zip folder.\nEnter a name for the “output” (optional)\n\nClick save parameters\nClick save and run to run the task.\nClick OK on the popup or the job will not start.\nClick on task again in your folder at the upper left if the task list is not present.\nView status if desired, refresh as needed, or just watch for the task done email.\nWhen it is done select the ‘view output’ for that task on the task list.\nDownload outputs and decompress. Job ‘inputs’ is displayed as garbage."
  },
  {
    "objectID": "menu/api/submitting-jobs.html#submitting-jobs-to-run-on-the-cri-hardware",
    "href": "menu/api/submitting-jobs.html#submitting-jobs-to-run-on-the-cri-hardware",
    "title": "HiAER-Spike",
    "section": "",
    "text": "The same Python scripts you’ve developed and run on your local machine can be deployed to the CRI servers to run on the actual CRI hardware. Just make sure all the libraries you import in your script are available on the CRI servers. The CRI hardware is hosted in the San Diego Supercomputing Center and jobs may be submitted to run on the hardware via the Neuroscience Gateway. First you must register an account with Neuroscience Gateway in order to submit jobs. Perform the following steps to submit a task to NSG\n\nPut your CRI Python script in a folder of any name, then zip the folder\nLog into NSG.\n\n\n\nCreate a task folder if there is none listed on the upper left. It’s a place to hold related jobs.\n\n\n\nClick on data, and save the previously created zip file as the data. Here ‘data’ is ambiguous - it is the job and its data.\nClick on task.\nCreate a new task if needed (or clone an old one).\nAssign the zip you just uploaded as data as the input to the task.\nSelect Python for CRI as the software to run.\nSet parameters for the task:\n\nSet execution ‘wall time’, cores, and GB of DRAM if you wish. Please be consideret to others and only request the hardware you need.\nEnter the name of your.py python scrip as the “input” using the same name as is in the zip folder.\nEnter a name for the “output” (optional)\n\nClick save parameters\nClick save and run to run the task.\nClick OK on the popup or the job will not start.\nClick on task again in your folder at the upper left if the task list is not present.\nView status if desired, refresh as needed, or just watch for the task done email.\nWhen it is done select the ‘view output’ for that task on the task list.\nDownload outputs and decompress. Job ‘inputs’ is displayed as garbage."
  },
  {
    "objectID": "menu/api/submitting-jobs.html#python-libraries-installed-on-the-cri-servers",
    "href": "menu/api/submitting-jobs.html#python-libraries-installed-on-the-cri-servers",
    "title": "HiAER-Spike",
    "section": "Python libraries installed on the CRI servers",
    "text": "Python libraries installed on the CRI servers\n\n\n\nLibrary\nVersion\n\n\n\n\nabsl-py\n1.1.0\n\n\nbidict\n0.22.0\n\n\nbrotlipy\n0.7.0\n\n\ncertifi\n2021.10.8\n\n\ncffi\n1.15.0\n\n\ncharset-normalizer\n2.0.4\n\n\nclick\n8.1.3\n\n\ncolorama\n0.4.4\n\n\nconda\n4.12.0\n\n\nconda-content-trust\n0+unknown\n\n\nconda-package-handling\n1.8.1\n\n\nconfuse\n1.7.0\n\n\ncri-simulations\n0.1.2\n\n\ncryptography\n36.0.0\n\n\ncycler\n0.11.0\n\n\nfbpca\n1.0\n\n\nfonttools\n4.33.3\n\n\nidna\n3.3\n\n\njoblib\n1.1.0\n\n\nk-means-constrained\n0.7.1\n\n\nkiwisolver\n1.4.3\n\n\nl2s\n0.1.3\n\n\nllvmlite\n0.38.1\n\n\nmatplotlib\n3.5.2\n\n\nmetis\n0.2a5\n\n\nnetworkx\n2.8.4\n\n\nnumba\n0.55.2\n\n\nnumpy\n1.22.4\n\n\nortools\n9.3.10497\n\n\npackaging\n21.3\n\n\nPillow\n9.1.1\n\n\npip\n21.2.4\n\n\nprotobuf\n4.21.1\n\n\npycosat\n0.6.3\n\n\npycparser\n2.21\n\n\nPyMetis\n2020.1\n\n\npyOpenSSL\n22.0.0\n\n\npyparsing\n3.0.9\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.8.2\n\n\nPyYAML\n6.0\n\n\nrequests\n2.27.1\n\n\nruamel-yaml-conda\n0.15.100\n\n\nscikit-learn\n1.1.1\n\n\nscipy\n1.8.1\n\n\nsetuptools\n61.2.0\n\n\nsix\n1.16.0\n\n\nsklearn\n0.0\n\n\nthreadpoolctl\n3.1.0\n\n\ntqdm\n4.63.0\n\n\nurllib3\n1.26.8\n\n\nwheel\n0.37.1"
  },
  {
    "objectID": "menu/api/usage.html",
    "href": "menu/api/usage.html",
    "title": "Usage",
    "section": "",
    "text": "Running on the Simulator\nOn your local machine you can run networks using the Python based simulator of the CRI hardware.\n\n\nDefining a Network\nUsers are expected to provide three data structures in order to define a network\n\nDefining the Configuration Dictionary\nThe configuration dictionary specifies a few properties that are shared by every neuron in the network\n\nneuron_type specifies the type of neuron model used to calculate membrane potentials\nglobal_neuron_params is a sub-dictionary of the configuration dictionary\n\nv_thr is an entry in the global_neuron_params dictionary, it sets the membrane potential threshold for all neurons in the network\n\n\nconfiguration = {}\nconfiguration[neuron_type'] = I&F\nconfiguration['global_neuron_params'] = {}\nconfiguration['global_neuron_params']['v_thr'] = 4\n\nDefining the Axons Dictionary\nThe axons dictionary configures inputs to the network. Axons are synapses connected to neurons in the network that the user can manually send spikes over at a given timestep. Each key in the dictionary is the name of an axon. Each value is a list of two element tuples. Each tuple defines an in-going synapse to a neuron. The first element is the name of a neuron in the network and the second element is the weight of the synaptic connection. Synapse weights must be integers, but they may be positive or negative.\n\naxons = {'alpha': [('a', 3)], 'beta': [('d', 3)]}\n\nDefining the Connections Dictionary:\nThe connections dictionary defines the neurons in the network and the connections between them. Each key in the dictionary is the name of a neuron. Of note the names of neurons in the connections dictionary and the names of axons in the axons dictionary must be mutually exclusive. Each value is a list of two element tuples. Each tuple defines a synapse between neurons in the network. The first element is the name of the postsynaptic neuron and the the second element is the weight of the synapse. Synapse weights must be integers but they may be positive or negative. If a neuron has no outgoing synapses it’s synapse list may be left empty.\n\nconnections = {'a': [('b', 1)], 'b': [], 'c': [], 'd': [('c', 1)]}\n\nDefining the Outputs List:\nThe outputs list defines the neurons in the network the user wishes to receive spikes from. Each element in the list is the key of a neuron in the connections dictionary.\n\noutputs = ['a', 'b']\n\n\nDefining Stochastic Behavior\nHiAER-Spike supports randomly perturbing the membrane potential of neurons at each timestep of execution. To enable this perturbation the perturb variable is set to True. The amplitude of this perturbation can also be scaled by setting the perturbMag variable (default = 0). perturbMag takes integer values between 0 and 18 and multiplies the random noise to be added to the membrane potential by 2perturbMag.\nperturb = True\nperturbMag = 2\n\n\nInitializing a network\nOnce we’ve defined the above dictionaries and list we must pass them to the CRI_network constructor to create a CRI_network object.\nnetwork = CRI_network(\n    axons=axons,\n    connections=connections,\n    config=config,\n    outputs=outputs,\n    perturb=perturb,\n    perturbMag=perturbMag\n)\n\n\nRunning a Timestep\nOnce we’ve constructed an CRI_network object we can run a timestep. We do so by calling the step() method of CRI_network. This method expects a single input called inputs. Inputs defines the inputs to the network at the current timestep, in particular it is a list of names of axons that you wish to carry spikes into the network at the current timestep. Normally network.step() returns a list of the keys that correspond to neurons that spiked during the given timestep, however the membranePotential parameter can be set to True to additionally output the membranePotentials for all neurons in the network.\ninputs = ['alpha','beta']\nspikes = network.step(inputs)\n\n#Alternative\npotentials, spikes = network.step(inputs, membranePotential=True)\nThis method will return a list of membrane potentials for all neurons in the network after the current timestep has elapsed.\n\n\nUpdating Synapse Weights\nOnce the CRI_network class the topology of the network is fixed, that is what axon and neurons are in the network and how they are connected via synapses may not be changed. However it is possible to update the weight of preexisting synapses in the network. This can be done by calling the write_synapse() method of CRI_network. write_synapse() takes three arguments, the presynaptic neuron name, the postsynaptic neuron name, and the new synapse weight.\nnetwork.write_synapse('a', 'b', 2)"
  },
  {
    "objectID": "menu/tutorials/cnn.html",
    "href": "menu/tutorials/cnn.html",
    "title": "Convolutional SNN",
    "section": "",
    "text": "Convolutional SNN\n\nClassifying Fashion-MNIST with Convolutional SNN\n  \nThis tutorial goes over how to train a convolutional spiking neural network (CSNN) on the Fashion-MNIST dataset and deploy on HiAER Spike using our conversion pipline.\n\n\nDefine a CSNN\nTo build a CSNN with PyTorch, we can use snnTorch, SpikingJelly or other deep learning frameworks that are based on PyTorch. Currently, our conversion pipline supports snnTorch and SpikingJelly. In this tutorial, we will be using SpikingJelly.\nInstall the PyPi distribution of SpikingJelly\n$ pip install spikingjelly\nImport necessary libraries from SpikingJelly and PyTorch\nfrom spikingjelly.activation_based import neuron, functional, surrogate, layer\nimport torch \nimport torch.nn as nn\n\n\nModel Architecture\nUsing SpikingJelly, we can define a CSNN with the architecture of 8C3-BN-6272FC10 - 8C3: a 3x3 convolutional kernel with 8 channels - BN: batch normalization layer - 6272FC10: the fully connected output layer\n\nSurrogate Function\nSpikingJelly and snnTorch both use backpropagation through time to train the spiking neural networks. However, because of the non-differentiability of spikes, surrogate gradients are used in place of the Heaviside function in the backward pass\nclass model(nn.Module): \n    def __init__(self, channels=8): \n        super().__init__()\n        self.conv = nn.Conv2d(1, channels, kernel_size=3, padding=1, bias=False)\n        self.bn = nn.BatchNorm2d(channels)\n        self.lif1 = neuron.IFNode(surrogate_function=surrogate.ATan())\n        self.flat = nn.Flatten()\n        self.linear = nn.Linear(channels * 28 * 28, 10, bias=False)\n        self.lif2 = neuron.IFNode(surrogate_function=surrogate.ATan())\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.lif1(x)\n        x = self.flat(x)\n        x = self.linear(x)\n        x = self.lif2(x)\n        return x\n#Initiate the Network\nnet = model()\n\n\n\nSetting up the Fashion-MNIST Dataset\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n#Download Fashion-MNIST data from torch \nfashion_mnist_train = datasets.FashionMNIST('data/fashion_mnist', train=True, download=True, transform=transforms.Compose(\n    [transforms.ToTensor()]))\nfashion_mnist_test = datasets.FashionMNIST('data/fashion_mnist', train=False, download=True, transform=transforms.Compose(\n    [transforms.ToTensor()]))\n\n# Create DataLoaders\ntrain_loader = DataLoader(fashion_mnist_train, batch_size=128, shuffle=True, drop_last=True)\ntest_loader = DataLoader(fashion_mnist_test, batch_size=128, shuffle=True, drop_last=True)\n\n\nTraining the SNN\nSince we are using a static image dataset, we will first encode the image into spikes using the rate encoding function from spikingjelly. With rate encoding, the input feature determines the firing frequency and the neuron that fries the most is selected as the predicted class.\nfrom spikingjelly.activation_based import encoding\nimport time\nfrom tqdm import tqdm\n#Setting up the encoder and the time steps\nencoder = encoding.PoissonEncoder()\nnum_steps = 40\n\n#Define training parameters\nepochs = 20\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n#Copy netowrk to device \nnet.to(device)\n\n#Define optimizer, scheduler and the loss function\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\nloss_fun = torch.nn.MSELoss()\nfor epoch in range(epochs):\n    start_time = time.time()\n    net.train()\n    train_loss = 0\n    train_acc = 0\n    train_samples = 0\n    for img, label in train_loader:\n        optimizer.zero_grad()\n        img = img.to(device)\n        label = label.to(device)\n        label_onehot = torch.nn.functional.one_hot(label, 10).float()\n        out_fr = 0.\n        for t in range(num_steps):\n            encoded_img = encoder(img)\n            out_fr += net(encoded_img)\n        out_fr = out_fr/num_steps  \n        loss = loss_fun(out_fr, label_onehot)\n        loss.backward()\n        optimizer.step()\n\n        train_samples += label.numel()\n        train_loss += loss.item() * label.numel()\n        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n\n        #reset the membrane protential after each input image\n        functional.reset_net(net)\n\n    train_time = time.time()\n    train_speed = train_samples / (train_time - start_time)\n    train_loss /= train_samples\n    train_acc /= train_samples\n    \n    lr_scheduler.step()\n        \n    net.eval()\n    test_loss = 0\n    test_acc = 0\n    test_samples = 0\n\n    with torch.no_grad():\n        for img, label in test_loader:\n            img = img.to(device)\n            label = label.to(device)\n            label_onehot = torch.nn.functional.one_hot(label, 10).float()\n            out_fr = 0.   \n            for t in range(num_steps):\n                encoded_img = encoder(img)\n                out_fr += net(encoded_img)\n            out_fr = out_fr/num_steps  \n\n            loss = loss_fun(out_fr, label_onehot)\n\n            test_samples += label.numel()\n            test_loss += loss.item() * label.numel()\n            test_acc += (out_fr.argmax(1) == label).float().sum().item()\n            functional.reset_net(net)\n\n    test_time = time.time()\n    test_speed = test_samples / (test_time - train_time)\n    test_loss /= test_samples\n    test_acc /= test_samples\n\n    print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\n    print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n\n\nConverting the trained SNN to HiAER Spike Format\nfrom hs_api.converter import CRI_Converter, Quantize_Network, BN_Folder\nfrom hs_api.api import CRI_network\n# import hs_bridge #Uncomment when running on FPGA\n\n#Fold the BN layer \nbn = BN_Folder() \nnet_bn = bn.fold(net)\n\n#Weight, Bias Quantization \nqn = Quantize_Network() \nnet_quan = qn.quantize(net_bn)\n\n#Set the parameters for conversion\ninput_layer = 0 #first pytorch layer that acts as synapses\noutput_layer = 4 #last pytorch layer that acts as synapses\ninput_shape = (1, 28, 28)\nbackend = 'spikingjelly'\nv_threshold = qn.v_threshold\n\n\nInitiate the HiAER Spike SNN\nconfig = {}\nconfig['neuron_type'] = \"I&F\"\nconfig['global_neuron_params'] = {}\nconfig['global_neuron_params']['v_thr'] = int(quan_fun.v_threshold)\n    \n# #Uncomment this to create a network running on the FPGA\n# hardwareNetwork = CRI_network(dict(cri_convert.axon_dict),\n#                               connections=dict(cri_convert.neuron_dict),\n#                               config=config,target='CRI', \n#                               outputs = cri_convert.output_neurons,\n#                               coreID=1)\n\nsoftwareNetwork = CRI_network(dict(cri_convert.axon_dict),\n                              connections=dict(cri_convert.neuron_dict),\n                              config=config,target='simpleSim', \n                              outputs = cri_convert.output_neurons,\n                              coreID=1)\n\n\nDeploying the SNN on HiAER Spike\nrun_sw and run_hw are two helper functions for running the spiking neural network\ndef Run_sw(self,inputList,softwareNetwork):\n    predictions = []\n    total_time_cri = 0\n    #each image\n    for currInput in tqdm(inputList):\n        #reset the membrane potential to zero\n        softwareNetwork.simpleSim.initialize_sim_vars(len(self.neuron_dict))\n        spikeRate = [0]*10\n        #each time step\n        for slice in currInput:\n            start_time = time.time()\n            swSpike = softwareNetwork.step(slice, membranePotential=False)\n\n            end_time = time.time()\n            total_time_cri = total_time_cri + end_time-start_time\n            for spike in swSpike:\n                spikeIdx = int(spike) - self.bias_start_idx \n                try: \n                    if spikeIdx &gt;= 0: \n                        spikeRate[spikeIdx] += 1 \n                except:\n                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate)\n        predictions.append(spikeRate.index(max(spikeRate)))\n    print(f\"Total simulation execution time: {total_time_cri:.5f} s\")\n    return(predictions)\ndef run_CRI_hw(self,inputList,hardwareNetwork):\n    predictions = []\n    #each image\n    total_time_cri = 0\n    for currInput in tqdm(inputList):\n        #initiate the hardware for each image\n        hs_bridge.FPGA_Execution.fpga_controller.clear(len(self.neuron_dict), False, 0)  ##Num_neurons, simDump, coreOverride\n        spikeRate = [0]*10\n        #each time step\n        for slice in tqdm(currInput):\n            start_time = time.time()\n            hwSpike, latency, hbmAcc = hardwareNetwork.step(slice, membranePotential=False)\n            print(f'hwSpike: {hwSpike}\\n. latency : {latency}\\n. hbmAcc:{hbmAcc}')\n            end_time = time.time()\n            total_time_cri = total_time_cri + end_time-start_time\n            for spike in hwSpike:\n                # print(int(spike))\n                spikeIdx = int(spike) - self.bias_start_idx \n                try: \n                    if spikeIdx &gt;= 0: \n                        spikeRate[spikeIdx] += 1 \n                except:\n                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate)\n        predictions.append(spikeRate.index(max(spikeRate))) \n    print(f\"Total execution time CRIFPGA: {total_time_cri:.5f} s\")\n    return(predictions)\ncri_convert.bias_start_idx = int(cri_convert.output_neurons[0])\nloss_fun = nn.MSELoss()\nstart_time = time.time()\ntest_loss = 0\ntest_acc = 0\ntest_samples = 0\nnum_batches = 0\n\nRUN_HARDWARE = False #Set to True if running on FPGA\n\nfor img, label in tqdm(test_loader):\n    cri_input = cri_convert.input_converter(img)\n    output = None\n    if RUN_HARDWARE:\n        output = torch.tensor(run_CRI_hw(cri_input,hardwareNetwork), dtype=float)\n    else:\n        output = torch.tensor(run_CRI_sw(cri_input,softwareNetwork), dtype=float)\n    loss = loss_fun(output, label)\n    test_samples += label.numel()\n    test_loss += loss.item() * label.numel()\n    test_acc += (output == label).float().sum().item()\n    num_batches += 1\ntest_time = time.time()\ntest_speed = test_samples / (test_time - start_time)\ntest_loss /= test_samples\ntest_acc /= test_samples\n\nprint(f'test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\nprint(f'test speed ={test_speed: .4f} images/s')"
  },
  {
    "objectID": "menu/tutorials/mnist.html",
    "href": "menu/tutorials/mnist.html",
    "title": "MNIST",
    "section": "",
    "text": "MNIST\n\nFeedforward Fully Connected SNN\n  \nThis tutorial goes over how to train a simple feedforward SNN and deploy on HiAER Spike using our conversion pipline.\n\n\nDefine a Feedforward SNN\nTo build a simple feedforward spiking neural network with PyTorch, we can use snnTorch, SpikingJelly or other deep learning frameworks that are based on PyTorch. Currently, our conversion pipline supports snnTorch and SpikingJelly. In this tutorial, we will be using SpikingJelly.\nInstall the PyPi distribution of SpikingJelly\n$ pip install spikingjelly\nImport necessary libraries from SpikingJelly and PyTorch\nfrom spikingjelly.activation_based import neuron, functional, surrogate, layer\nimport torch \nimport torch.nn as nn\n\n\nModel Architecture\nUsing SpikingJelly, we can define a simple 2-layer feedforward SNN model with 1000 hidden neurons. The PyTorch layer will act as synapses between the spiking neuron layers. #### Surrogate Function SpikingJelly and snnTorch both use backpropagation through time to train the spiking neural networks. However, because of the non-differentiability of spikes, surrogate gradients are used in place of the Heaviside function in the backward pass.\nclass model(nn.Module): \n    def __init__(self, features = 1000): \n        super().__init__() \n        self.flat = nn.Flatten()\n        self.linear1 = nn.Linear(28 * 28, features, bias=False) \n        self.lif1 = neuron.LIFNode(surrogate_function=surrogate.ATan()) \n        self.linear2 = nn.Linear(features, 10, bias=False) \n        self.lif2 = neuron.LIFNode(surrogate_function=surrogate.ATan()) \n    def forward(self, x): \n        x = self.flat(x)\n        x = self.linear1(x) \n        x = self.lif1(x) \n        x = self.linear2(x) \n        x = self.lif2(x) \n        return x\n#Initiate the Network\nnet = model()\n\n\nSetting up the MNIST Dataset\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n#Download MNIST data from torch \nmnist_train = datasets.MNIST('data/mnist', train=True, download=True, transform=transforms.Compose(\n    [transforms.ToTensor()]))\nmnist_test = datasets.MNIST('data/mnist', train=False, download=True, transform=transforms.Compose(\n    [transforms.ToTensor()]))\n\n# Create DataLoaders\ntrain_loader = DataLoader(mnist_train, batch_size=128, shuffle=True, drop_last=True)\ntest_loader = DataLoader(mnist_test, batch_size=128, shuffle=True, drop_last=True)\n\n\nTraining the CSNN\nSince we are using a static image dataset, we will first encode the image into spikes using the rate encoding function from spikingjelly. With rate encoding, the input feature determines the firing frequency and the neuron that fries the most is selected as the predicted class.\nfrom spikingjelly.activation_based import encoding\nimport time\nfrom tqdm import tqdm\n#Setting up the encoder and the time steps\nencoder = encoding.PoissonEncoder()\nnum_steps = 20\n\n#Define training parameters\nepochs = 20\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n#Copy netowrk to device \nnet.to(device)\n\n#Define optimizer, scheduler and the loss function\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\nloss_fun = torch.nn.MSELoss()\nfor epoch in range(epochs):\n    start_time = time.time()\n    net.train()\n    train_loss = 0\n    train_acc = 0\n    train_samples = 0\n    for img, label in train_loader:\n        optimizer.zero_grad()\n        img = img.to(device)\n        label = label.to(device)\n        label_onehot = torch.nn.functional.one_hot(label, 10).float()\n        out_fr = 0.\n        for t in range(num_steps):\n            encoded_img = encoder(img)\n            out_fr += net(encoded_img)\n        out_fr = out_fr/num_steps  \n        loss = loss_fun(out_fr, label_onehot)\n        loss.backward()\n        optimizer.step()\n\n        train_samples += label.numel()\n        train_loss += loss.item() * label.numel()\n        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n\n        #reset the membrane protential after each input image\n        functional.reset_net(net)\n\n    train_time = time.time()\n    train_speed = train_samples / (train_time - start_time)\n    train_loss /= train_samples\n    train_acc /= train_samples\n    \n    lr_scheduler.step()\n        \n    net.eval()\n    test_loss = 0\n    test_acc = 0\n    test_samples = 0\n\n    with torch.no_grad():\n        for img, label in test_loader:\n            img = img.to(device)\n            label = label.to(device)\n            label_onehot = torch.nn.functional.one_hot(label, 10).float()\n            out_fr = 0.   \n            for t in range(num_steps):\n                encoded_img = encoder(img)\n                out_fr += net(encoded_img)\n            out_fr = out_fr/num_steps  \n\n            loss = loss_fun(out_fr, label_onehot)\n\n            test_samples += label.numel()\n            test_loss += loss.item() * label.numel()\n            test_acc += (out_fr.argmax(1) == label).float().sum().item()\n            functional.reset_net(net)\n\n    test_time = time.time()\n    test_speed = test_samples / (test_time - train_time)\n    test_loss /= test_samples\n    test_acc /= test_samples\n\n    print(f'epoch = {epoch}, train_loss ={train_loss: .4f}, train_acc ={train_acc: .4f}, test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\n    print(f'train speed ={train_speed: .4f} images/s, test speed ={test_speed: .4f} images/s')\n\n\nConverting the trained SNN to HiAER Spike Format\nfrom hs_api.converter import CRI_Converter, Quantize_Network, BN_Folder\nfrom hs_api.api import CRI_network\n# import hs_bridge #Uncomment when running on FPGA\n\n#Fold the BN layer \nbn = BN_Folder() \nnet_bn = bn.fold(net)\n\n#Weight, Bias Quantization \nqn = Quantize_Network() \nnet_quan = qn.quantize(net_bn)\n\n#Set the parameters for conversion\ninput_layer = 1 #first pytorch layer that acts as synapses\noutput_layer = 4 #last pytorch layer that acts as synapses\ninput_shape = (1, 28, 28)\nbackend = 'spikingjelly'\nv_threshold = qn.v_threshold\n\n\nInitiate the HiAER Spike SNN\nconfig = {}\nconfig['neuron_type'] = \"I&F\"\nconfig['global_neuron_params'] = {}\nconfig['global_neuron_params']['v_thr'] = int(quan_fun.v_threshold)\n    \n# #Uncomment this to create a network running on the FPGA\n# hardwareNetwork = CRI_network(dict(cri_convert.axon_dict),\n#                               connections=dict(cri_convert.neuron_dict),\n#                               config=config,target='CRI', \n#                               outputs = cri_convert.output_neurons,\n#                               coreID=1)\n\nsoftwareNetwork = CRI_network(dict(cri_convert.axon_dict),\n                              connections=dict(cri_convert.neuron_dict),\n                              config=config,target='simpleSim', \n                              outputs = cri_convert.output_neurons,\n                              coreID=1)\n\n\nDeploying the SNN on HiAER Spike\nrun_sw and run_hw are two helper functions for running the spiking neural network\ndef Run_sw(self,inputList,softwareNetwork):\n    predictions = []\n    total_time_cri = 0\n    #each image\n    for currInput in tqdm(inputList):\n        #reset the membrane potential to zero\n        softwareNetwork.simpleSim.initialize_sim_vars(len(self.neuron_dict))\n        spikeRate = [0]*10\n        #each time step\n        for slice in currInput:\n            start_time = time.time()\n            swSpike = softwareNetwork.step(slice, membranePotential=False)\n\n            end_time = time.time()\n            total_time_cri = total_time_cri + end_time-start_time\n            for spike in swSpike:\n                spikeIdx = int(spike) - self.bias_start_idx \n                try: \n                    if spikeIdx &gt;= 0: \n                        spikeRate[spikeIdx] += 1 \n                except:\n                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate)\n        predictions.append(spikeRate.index(max(spikeRate)))\n    print(f\"Total simulation execution time: {total_time_cri:.5f} s\")\n    return(predictions)\ndef run_CRI_hw(self,inputList,hardwareNetwork):\n    predictions = []\n    #each image\n    total_time_cri = 0\n    for currInput in tqdm(inputList):\n        #initiate the hardware for each image\n        hs_bridge.FPGA_Execution.fpga_controller.clear(len(self.neuron_dict), False, 0)  ##Num_neurons, simDump, coreOverride\n        spikeRate = [0]*10\n        #each time step\n        for slice in tqdm(currInput):\n            start_time = time.time()\n            hwSpike, latency, hbmAcc = hardwareNetwork.step(slice, membranePotential=False)\n            print(f'hwSpike: {hwSpike}\\n. latency : {latency}\\n. hbmAcc:{hbmAcc}')\n            end_time = time.time()\n            total_time_cri = total_time_cri + end_time-start_time\n            for spike in hwSpike:\n                # print(int(spike))\n                spikeIdx = int(spike) - self.bias_start_idx \n                try: \n                    if spikeIdx &gt;= 0: \n                        spikeRate[spikeIdx] += 1 \n                except:\n                    print(\"SpikeIdx: \", spikeIdx,\"\\n SpikeRate:\",spikeRate)\n        predictions.append(spikeRate.index(max(spikeRate))) \n    print(f\"Total execution time CRIFPGA: {total_time_cri:.5f} s\")\n    return(predictions)\ncri_convert.bias_start_idx = int(cri_convert.output_neurons[0])\nloss_fun = nn.MSELoss()\nstart_time = time.time()\ntest_loss = 0\ntest_acc = 0\ntest_samples = 0\nnum_batches = 0\n\nRUN_HARDWARE = False #Set to True if running on FPGA\n\nfor img, label in tqdm(test_loader):\n    cri_input = cri_convert.input_converter(img)\n    output = None\n    if RUN_HARDWARE:\n        output = torch.tensor(run_CRI_hw(cri_input,hardwareNetwork), dtype=float)\n    else:\n        output = torch.tensor(run_CRI_sw(cri_input,softwareNetwork), dtype=float)\n    loss = loss_fun(output, label)\n    test_samples += label.numel()\n    test_loss += loss.item() * label.numel()\n    test_acc += (output == label).float().sum().item()\n    num_batches += 1\ntest_time = time.time()\ntest_speed = test_samples / (test_time - start_time)\ntest_loss /= test_samples\ntest_acc /= test_samples\n\nprint(f'test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\nprint(f'test speed ={test_speed: .4f} images/s')"
  },
  {
    "objectID": "reference/api.CRI_network.html",
    "href": "reference/api.CRI_network.html",
    "title": "api.CRI_network",
    "section": "",
    "text": "api.CRI_network(self, axons, connections, config, outputs, target=None, simDump=False, coreID=0, perturb=False, perturbMag=0)\nThis class represents a CRI network which initializes the network, checks hardware, generates connectome, formats input, reads and writes synapse, and runs simulation steps.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nuserAxons\ndict\nA copy of the axons dictionary provided by the user.\n\n\nuserConnections\ndict\nA copy of the connections dictionary provided by the user.\n\n\nconfig\ndict\nThe configuration parameters for the network.\n\n\nperturb\nbool\nA boolean value indicating whether to perturb the network.\n\n\nperturbMag\nint\nThe magnitude of perturbation.\n\n\nsimpleSim\nstr\nA string representing the simple simulation.\n\n\nkey2index\ndict\nA dictionary mapping keys to indices.\n\n\nsimDump\nbool\nA boolean value indicating whether to dump simulation results.\n\n\nconnectome\nstr\nA string representing the connectome of the network.\n\n\naxons\ndict\nThe formatted axons dictionary.\n\n\nconnections\ndict\nThe formatted connections dictionary.\n\n\n\n\n\n\ncheckHw, gen_connectome, __format_input, write_synapse, write_listofSynapses, read_synapse, sim_flush, step, run_cont\n\n\n\n&gt;&gt;&gt; axons = {'axon1': [('neuron1', 1), ('neuron2', 2)]}\n&gt;&gt;&gt; connections = {'neuron1': [('axon1', 1)], 'neuron2': [('axon1', 2)]}\n&gt;&gt;&gt; config = {'neuron_type': 'type1', 'global_neuron_params': {'v_thr': 1.0}}\n&gt;&gt;&gt; outputs = ['output1', 'output2']\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncheckHw\nChecks if the magic file exists to demark that we’re running on a system with CRI hardware accessible.\n\n\ngen_connectome\nGenerates a connectome for the CRI network.\n\n\nread_synapse\nReads a synapse from the connectome.\n\n\nrun_cont\nRuns a continuous simulation.\n\n\nsim_flush\nFlushes the simulation results to a file.\n\n\nstep\nRuns a step of the simulation.\n\n\nwrite_listofSynapses\nWrites a list of synapses to the connectome.\n\n\nwrite_synapse\nWrites a synapse to the connectome.\n\n\n\n\n\napi.CRI_network.checkHw(self)\nChecks if the magic file exists to demark that we’re running on a system with CRI hardware accessible.\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool\nTrue if the magic file exists, False otherwise.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.checkHw()\nTrue\n\n\n\n\napi.CRI_network.gen_connectome(self)\n\n\nThe function resets the count of neurons and creates a new connectome. It then adds neurons/axons and assigns synapses to them.\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.gen_connectome()\n\n\n\n\napi.CRI_network.read_synapse(self, preKey, postKey)\nReads a synapse from the connectome.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreKey\nstr\nA string representing the key of the presynaptic neuron.\nrequired\n\n\npostKey\nstr\nA string representing the key of the postsynaptic neuron.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nThe weight of the synapse.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is not valid (“simpleSim” or “CRI”).\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.read_synapse('axon1', 'neuron1')\n1\n\n\n\n\napi.CRI_network.run_cont(self, inputs)\nRuns a continuous simulation.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninputs\nlist of list\nA list of lists of inputs for the simulation.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntuple\nA tuple containing the spike list, a boolean indicating whether a break occurred, and the execution counter.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the simulation dump flag is False and an error occurs during the conversion of neuron indices to user keys.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.run_cont([['input1', 'input2'], ['input3', 'input4']])\n\n\n\n\napi.CRI_network.sim_flush(self, file)\nFlushes the simulation results to a file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile\nstr\nA string representing the file to which to flush the simulation results.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is not “CRI” or if the target is invalid.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.sim_flush('results.txt')\n\n\n\n\napi.CRI_network.step(self, inputs, target='simpleSim', membranePotential=False)\nRuns a step of the simulation.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninputs\nlist\nA list of inputs for the simulation.\nrequired\n\n\ntarget\nstr\nA string representing the target for the simulation. Default is “simpleSim”.\n'simpleSim'\n\n\nmembranePotential\nbool\nA boolean value indicating whether to return the membrane potential. Default is False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist or tuple\nThe simulation outputs or a tuple containing the simulation outputs and spike outputs.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is invalid.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.step(['input1', 'input2'])\n\n\n\n\napi.CRI_network.write_listofSynapses(self, preKeys, postKeys, weights)\nWrites a list of synapses to the connectome.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreKeys\nlist of str\nA list of strings representing the keys of the presynaptic neurons.\nrequired\n\n\npostKeys\nlist of str\nA list of strings representing the keys of the postsynaptic neurons.\nrequired\n\n\nweights\nlist of int\nA list of integers representing the weights of the synapses.\nrequired\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; preKeys = ['axon1', 'axon2']\n&gt;&gt;&gt; postKeys = ['neuron1', 'neuron2']\n&gt;&gt;&gt; weights = [1, 2]\n&gt;&gt;&gt; network.write_listofSynapses(preKeys, postKeys, weights)\n\n\n\n\napi.CRI_network.write_synapse(self, preKey, postKey, weight)\nWrites a synapse to the connectome.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreKey\nstr\nA string representing the key of the presynaptic neuron.\nrequired\n\n\npostKey\nstr\nA string representing the key of the postsynaptic neuron.\nrequired\n\n\nweight\nint\nAn integer representing the weight of the synapse.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is not valid (“simpleSim” or “CRI”).\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.write_synapse('axon1', 'neuron1', 1)"
  },
  {
    "objectID": "reference/api.CRI_network.html#attributes",
    "href": "reference/api.CRI_network.html#attributes",
    "title": "api.CRI_network",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nuserAxons\ndict\nA copy of the axons dictionary provided by the user.\n\n\nuserConnections\ndict\nA copy of the connections dictionary provided by the user.\n\n\nconfig\ndict\nThe configuration parameters for the network.\n\n\nperturb\nbool\nA boolean value indicating whether to perturb the network.\n\n\nperturbMag\nint\nThe magnitude of perturbation.\n\n\nsimpleSim\nstr\nA string representing the simple simulation.\n\n\nkey2index\ndict\nA dictionary mapping keys to indices.\n\n\nsimDump\nbool\nA boolean value indicating whether to dump simulation results.\n\n\nconnectome\nstr\nA string representing the connectome of the network.\n\n\naxons\ndict\nThe formatted axons dictionary.\n\n\nconnections\ndict\nThe formatted connections dictionary."
  },
  {
    "objectID": "reference/api.CRI_network.html#see-also",
    "href": "reference/api.CRI_network.html#see-also",
    "title": "api.CRI_network",
    "section": "",
    "text": "checkHw, gen_connectome, __format_input, write_synapse, write_listofSynapses, read_synapse, sim_flush, step, run_cont"
  },
  {
    "objectID": "reference/api.CRI_network.html#examples",
    "href": "reference/api.CRI_network.html#examples",
    "title": "api.CRI_network",
    "section": "",
    "text": "&gt;&gt;&gt; axons = {'axon1': [('neuron1', 1), ('neuron2', 2)]}\n&gt;&gt;&gt; connections = {'neuron1': [('axon1', 1)], 'neuron2': [('axon1', 2)]}\n&gt;&gt;&gt; config = {'neuron_type': 'type1', 'global_neuron_params': {'v_thr': 1.0}}\n&gt;&gt;&gt; outputs = ['output1', 'output2']\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)"
  },
  {
    "objectID": "reference/api.CRI_network.html#methods",
    "href": "reference/api.CRI_network.html#methods",
    "title": "api.CRI_network",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncheckHw\nChecks if the magic file exists to demark that we’re running on a system with CRI hardware accessible.\n\n\ngen_connectome\nGenerates a connectome for the CRI network.\n\n\nread_synapse\nReads a synapse from the connectome.\n\n\nrun_cont\nRuns a continuous simulation.\n\n\nsim_flush\nFlushes the simulation results to a file.\n\n\nstep\nRuns a step of the simulation.\n\n\nwrite_listofSynapses\nWrites a list of synapses to the connectome.\n\n\nwrite_synapse\nWrites a synapse to the connectome.\n\n\n\n\n\napi.CRI_network.checkHw(self)\nChecks if the magic file exists to demark that we’re running on a system with CRI hardware accessible.\n\n\n\n\n\nType\nDescription\n\n\n\n\nbool\nTrue if the magic file exists, False otherwise.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.checkHw()\nTrue\n\n\n\n\napi.CRI_network.gen_connectome(self)\n\n\nThe function resets the count of neurons and creates a new connectome. It then adds neurons/axons and assigns synapses to them.\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.gen_connectome()\n\n\n\n\napi.CRI_network.read_synapse(self, preKey, postKey)\nReads a synapse from the connectome.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreKey\nstr\nA string representing the key of the presynaptic neuron.\nrequired\n\n\npostKey\nstr\nA string representing the key of the postsynaptic neuron.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\nThe weight of the synapse.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is not valid (“simpleSim” or “CRI”).\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.read_synapse('axon1', 'neuron1')\n1\n\n\n\n\napi.CRI_network.run_cont(self, inputs)\nRuns a continuous simulation.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninputs\nlist of list\nA list of lists of inputs for the simulation.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\ntuple\nA tuple containing the spike list, a boolean indicating whether a break occurred, and the execution counter.\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the simulation dump flag is False and an error occurs during the conversion of neuron indices to user keys.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.run_cont([['input1', 'input2'], ['input3', 'input4']])\n\n\n\n\napi.CRI_network.sim_flush(self, file)\nFlushes the simulation results to a file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfile\nstr\nA string representing the file to which to flush the simulation results.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is not “CRI” or if the target is invalid.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.sim_flush('results.txt')\n\n\n\n\napi.CRI_network.step(self, inputs, target='simpleSim', membranePotential=False)\nRuns a step of the simulation.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninputs\nlist\nA list of inputs for the simulation.\nrequired\n\n\ntarget\nstr\nA string representing the target for the simulation. Default is “simpleSim”.\n'simpleSim'\n\n\nmembranePotential\nbool\nA boolean value indicating whether to return the membrane potential. Default is False.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nlist or tuple\nThe simulation outputs or a tuple containing the simulation outputs and spike outputs.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is invalid.\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.step(['input1', 'input2'])\n\n\n\n\napi.CRI_network.write_listofSynapses(self, preKeys, postKeys, weights)\nWrites a list of synapses to the connectome.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreKeys\nlist of str\nA list of strings representing the keys of the presynaptic neurons.\nrequired\n\n\npostKeys\nlist of str\nA list of strings representing the keys of the postsynaptic neurons.\nrequired\n\n\nweights\nlist of int\nA list of integers representing the weights of the synapses.\nrequired\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; preKeys = ['axon1', 'axon2']\n&gt;&gt;&gt; postKeys = ['neuron1', 'neuron2']\n&gt;&gt;&gt; weights = [1, 2]\n&gt;&gt;&gt; network.write_listofSynapses(preKeys, postKeys, weights)\n\n\n\n\napi.CRI_network.write_synapse(self, preKey, postKey, weight)\nWrites a synapse to the connectome.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npreKey\nstr\nA string representing the key of the presynaptic neuron.\nrequired\n\n\npostKey\nstr\nA string representing the key of the postsynaptic neuron.\nrequired\n\n\nweight\nint\nAn integer representing the weight of the synapse.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nException\nIf the target is not valid (“simpleSim” or “CRI”).\n\n\n\n\n\n\n&gt;&gt;&gt; network = CRI_network(axons, connections, config, outputs)\n&gt;&gt;&gt; network.write_synapse('axon1', 'neuron1', 1)"
  },
  {
    "objectID": "reference/api.html",
    "href": "reference/api.html",
    "title": "api",
    "section": "",
    "text": "api\napi"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "hs_api:v0.1.0",
    "section": "",
    "text": "Reference for the hs_api package\n\n\n\napi\n\n\n\napi.CRI_network\nThis class represents a CRI network which initializes the network, checks hardware, generates connectome,"
  },
  {
    "objectID": "reference/index.html#api-reference",
    "href": "reference/index.html#api-reference",
    "title": "hs_api:v0.1.0",
    "section": "",
    "text": "Reference for the hs_api package\n\n\n\napi\n\n\n\napi.CRI_network\nThis class represents a CRI network which initializes the network, checks hardware, generates connectome,"
  }
]