[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to HiAER-Spike v0.1.0",
    "section": "",
    "text": "Welcome to HiAER-Spike v0.1.0\nHiAER-Spike is a python library for interacting with the ISN CRI project hosted at the San Diego Supercomputer (SDSC). This project aims to make massive scale simulations of spiking neural networks easily accessible to the research community, and in particular researches interested in neuromorphic computing for artificial intelligence and neuroscience researchers. This library allows a user to define a spiking neural network and execute it on one of two backends: the CRI neuromorphic hardware or if the hardware is not available a python simulation of the hardware."
  },
  {
    "objectID": "collab/mnist.html",
    "href": "collab/mnist.html",
    "title": "Feedforward Fully Connected SNN",
    "section": "",
    "text": "This tutorial goes over how to train a simple feedforward SNN and deploy on HiAER Spike using our conversion pipline.\n\nDefine a Feedforward SNN\nTo build a simple feedforward spiking neural network with PyTorch, we can use snnTorch, SpikingJelly or other deep learning frameworks that are based on PyTorch. Currently, our conversion pipline supports snnTorch and SpikingJelly. In this tutorial, we will be using SpikingJelly.\n\n\n\nERROR: Could not find a version that satisfies the requirement hs_api (from versions: none)\nERROR: No matching distribution found for hs_api\nNote: you may need to restart the kernel to use updated packages."
  },
  {
    "objectID": "menu/api/overview.html",
    "href": "menu/api/overview.html",
    "title": "Overview",
    "section": "",
    "text": "hs_api is a python library for interacting with the ISN CRI project hosted at SDSC. This project aims to make massive scale simulations of spiking neural networks easily accessible to the research community, and in particular researchers interested in neuromorphic computing for artificial intelligence and neuroscience. This library allows a user to define a spiking neural network and execute it on one of two backends:\n\nthe CRI neuromorphic hardware or\na python simulation of the hardware\n\nCheck out the Usage section for further information."
  },
  {
    "objectID": "menu/api/overview.html#introduction",
    "href": "menu/api/overview.html#introduction",
    "title": "Overview",
    "section": "",
    "text": "hs_api is a python library for interacting with the ISN CRI project hosted at SDSC. This project aims to make massive scale simulations of spiking neural networks easily accessible to the research community, and in particular researchers interested in neuromorphic computing for artificial intelligence and neuroscience. This library allows a user to define a spiking neural network and execute it on one of two backends:\n\nthe CRI neuromorphic hardware or\na python simulation of the hardware\n\nCheck out the Usage section for further information."
  },
  {
    "objectID": "menu/api/overview.html#installation",
    "href": "menu/api/overview.html#installation",
    "title": "Overview",
    "section": "Installation",
    "text": "Installation\n\nSimple Installation\n$ pip install hs_api\n\n\nDevelopment Installation\n\nFirst install Poetry\n\nIf Poetry doesn’t install it may be necessary to install an alternative Python distribution such as Conda\n\nClone the following dependencies and the hs_api repo:\n\n# Dependencies\n$ git clone https://github.com/Integrated-Systems-Neuroengineering/connectome_utils.git\n$ git clone  https://github.com/Integrated-Systems-Neuroengineering/hs_bridge.git\n\n# API repo\n$ git clone https://github.com/Integrated-Systems-Neuroengineering/hs_api.git\n\ncd into the hs_api repo you cloned and install the needed dependencies. Resolving dependencies may take a while.\n\n$ cd hs_api\n$ poetry install\n\nFinally activate the development environment\n\n$ poetry shell"
  },
  {
    "objectID": "menu/api/submitting-jobs.html",
    "href": "menu/api/submitting-jobs.html",
    "title": "HiAER-Spike",
    "section": "",
    "text": "The same Python scripts you’ve developed and run on your local machine can be deployed to the CRI servers to run on the actual CRI hardware. Just make sure all the libraries you import in your script are available on the CRI servers. The CRI hardware is hosted in the San Diego Supercomputing Center and jobs may be submitted to run on the hardware via the Neuroscience Gateway. First you must register an account with Neuroscience Gateway in order to submit jobs. Perform the following steps to submit a task to NSG\n\nPut your CRI Python script in a folder of any name, then zip the folder\nLog into NSG.\n\n\n\nCreate a task folder if there is none listed on the upper left. It’s a place to hold related jobs.\n\n\n\nClick on data, and save the previously created zip file as the data. Here ‘data’ is ambiguous - it is the job and its data.\nClick on task.\nCreate a new task if needed (or clone an old one).\nAssign the zip you just uploaded as data as the input to the task.\nSelect Python for CRI as the software to run.\nSet parameters for the task:\n\nSet execution ‘wall time’, cores, and GB of DRAM if you wish. Please be consideret to others and only request the hardware you need.\nEnter the name of your.py python scrip as the “input” using the same name as is in the zip folder.\nEnter a name for the “output” (optional)\n\nClick save parameters\nClick save and run to run the task.\nClick OK on the popup or the job will not start.\nClick on task again in your folder at the upper left if the task list is not present.\nView status if desired, refresh as needed, or just watch for the task done email.\nWhen it is done select the ‘view output’ for that task on the task list.\nDownload outputs and decompress. Job ‘inputs’ is displayed as garbage."
  },
  {
    "objectID": "menu/api/submitting-jobs.html#submitting-jobs-to-run-on-the-cri-hardware",
    "href": "menu/api/submitting-jobs.html#submitting-jobs-to-run-on-the-cri-hardware",
    "title": "HiAER-Spike",
    "section": "",
    "text": "The same Python scripts you’ve developed and run on your local machine can be deployed to the CRI servers to run on the actual CRI hardware. Just make sure all the libraries you import in your script are available on the CRI servers. The CRI hardware is hosted in the San Diego Supercomputing Center and jobs may be submitted to run on the hardware via the Neuroscience Gateway. First you must register an account with Neuroscience Gateway in order to submit jobs. Perform the following steps to submit a task to NSG\n\nPut your CRI Python script in a folder of any name, then zip the folder\nLog into NSG.\n\n\n\nCreate a task folder if there is none listed on the upper left. It’s a place to hold related jobs.\n\n\n\nClick on data, and save the previously created zip file as the data. Here ‘data’ is ambiguous - it is the job and its data.\nClick on task.\nCreate a new task if needed (or clone an old one).\nAssign the zip you just uploaded as data as the input to the task.\nSelect Python for CRI as the software to run.\nSet parameters for the task:\n\nSet execution ‘wall time’, cores, and GB of DRAM if you wish. Please be consideret to others and only request the hardware you need.\nEnter the name of your.py python scrip as the “input” using the same name as is in the zip folder.\nEnter a name for the “output” (optional)\n\nClick save parameters\nClick save and run to run the task.\nClick OK on the popup or the job will not start.\nClick on task again in your folder at the upper left if the task list is not present.\nView status if desired, refresh as needed, or just watch for the task done email.\nWhen it is done select the ‘view output’ for that task on the task list.\nDownload outputs and decompress. Job ‘inputs’ is displayed as garbage."
  },
  {
    "objectID": "menu/api/submitting-jobs.html#python-libraries-installed-on-the-cri-servers",
    "href": "menu/api/submitting-jobs.html#python-libraries-installed-on-the-cri-servers",
    "title": "HiAER-Spike",
    "section": "Python libraries installed on the CRI servers",
    "text": "Python libraries installed on the CRI servers\n\n\n\nLibrary\nVersion\n\n\n\n\nabsl-py\n1.1.0\n\n\nbidict\n0.22.0\n\n\nbrotlipy\n0.7.0\n\n\ncertifi\n2021.10.8\n\n\ncffi\n1.15.0\n\n\ncharset-normalizer\n2.0.4\n\n\nclick\n8.1.3\n\n\ncolorama\n0.4.4\n\n\nconda\n4.12.0\n\n\nconda-content-trust\n0+unknown\n\n\nconda-package-handling\n1.8.1\n\n\nconfuse\n1.7.0\n\n\ncri-simulations\n0.1.2\n\n\ncryptography\n36.0.0\n\n\ncycler\n0.11.0\n\n\nfbpca\n1.0\n\n\nfonttools\n4.33.3\n\n\nidna\n3.3\n\n\njoblib\n1.1.0\n\n\nk-means-constrained\n0.7.1\n\n\nkiwisolver\n1.4.3\n\n\nl2s\n0.1.3\n\n\nllvmlite\n0.38.1\n\n\nmatplotlib\n3.5.2\n\n\nmetis\n0.2a5\n\n\nnetworkx\n2.8.4\n\n\nnumba\n0.55.2\n\n\nnumpy\n1.22.4\n\n\nortools\n9.3.10497\n\n\npackaging\n21.3\n\n\nPillow\n9.1.1\n\n\npip\n21.2.4\n\n\nprotobuf\n4.21.1\n\n\npycosat\n0.6.3\n\n\npycparser\n2.21\n\n\nPyMetis\n2020.1\n\n\npyOpenSSL\n22.0.0\n\n\npyparsing\n3.0.9\n\n\nPySocks\n1.7.1\n\n\npython-dateutil\n2.8.2\n\n\nPyYAML\n6.0\n\n\nrequests\n2.27.1\n\n\nruamel-yaml-conda\n0.15.100\n\n\nscikit-learn\n1.1.1\n\n\nscipy\n1.8.1\n\n\nsetuptools\n61.2.0\n\n\nsix\n1.16.0\n\n\nsklearn\n0.0\n\n\nthreadpoolctl\n3.1.0\n\n\ntqdm\n4.63.0\n\n\nurllib3\n1.26.8\n\n\nwheel\n0.37.1"
  },
  {
    "objectID": "menu/api/usage.html",
    "href": "menu/api/usage.html",
    "title": "Usage",
    "section": "",
    "text": "Running on the Simulator\nOn your local machine you can run networks using the Python based simulator of the CRI hardware.\n\n\nDefining a Network\nUsers are expected to provide three data structures in order to define a network\n\nDefining the Configuration Dictionary\nThe configuration dictionary specifies a few properties that are shared by every neuron in the network\n\nneuron_type specifies the type of neuron model used to calculate membrane potentials\nglobal_neuron_params is a sub-dictionary of the configuration dictionary\n\nv_thr is an entry in the global_neuron_params dictionary, it sets the membrane potential threshold for all neurons in the network\n\n\nconfiguration = {}\nconfiguration[neuron_type'] = I&F\nconfiguration['global_neuron_params'] = {}\nconfiguration['global_neuron_params']['v_thr'] = 4\n\nDefining the Axons Dictionary\nThe axons dictionary configures inputs to the network. Axons are synapses connected to neurons in the network that the user can manually send spikes over at a given timestep. Each key in the dictionary is the name of an axon. Each value is a list of two element tuples. Each tuple defines an in-going synapse to a neuron. The first element is the name of a neuron in the network and the second element is the weight of the synaptic connection. Synapse weights must be integers, but they may be positive or negative.\n\naxons = {'alpha': [('a', 3)], 'beta': [('d', 3)]}\n\nDefining the Connections Dictionary:\nThe connections dictionary defines the neurons in the network and the connections between them. Each key in the dictionary is the name of a neuron. Of note the names of neurons in the connections dictionary and the names of axons in the axons dictionary must be mutually exclusive. Each value is a list of two element tuples. Each tuple defines a synapse between neurons in the network. The first element is the name of the postsynaptic neuron and the the second element is the weight of the synapse. Synapse weights must be integers but they may be positive or negative. If a neuron has no outgoing synapses it’s synapse list may be left empty.\n\nconnections = {'a': [('b', 1)], 'b': [], 'c': [], 'd': [('c', 1)]}\n\nDefining the Outputs List:\nThe outputs list defines the neurons in the network the user wishes to receive spikes from. Each element in the list is the key of a neuron in the connections dictionary.\n\noutputs = ['a', 'b']\n\n\nDefining Stochastic Behavior\nHiAER-Spike supports randomly perturbing the membrane potential of neurons at each timestep of execution. To enable this perturbation the perturb variable is set to True. The amplitude of this perturbation can also be scaled by setting the perturbMag variable (default = 0). perturbMag takes integer values between 0 and 18 and multiplies the random noise to be added to the membrane potential by 2perturbMag.\nperturb = True\nperturbMag = 2\n\n\nInitializing a network\nOnce we’ve defined the above dictionaries and list we must pass them to the CRI_network constructor to create a CRI_network object.\nnetwork = CRI_network(\n    axons=axons,\n    connections=connections,\n    config=config,\n    outputs=outputs,\n    perturb=perturb,\n    perturbMag=perturbMag\n)\n\n\nRunning a Timestep\nOnce we’ve constructed an CRI_network object we can run a timestep. We do so by calling the step() method of CRI_network. This method expects a single input called inputs. Inputs defines the inputs to the network at the current timestep, in particular it is a list of names of axons that you wish to carry spikes into the network at the current timestep. Normally network.step() returns a list of the keys that correspond to neurons that spiked during the given timestep, however the membranePotential parameter can be set to True to additionally output the membranePotentials for all neurons in the network.\ninputs = ['alpha','beta']\nspikes = network.step(inputs)\n\n#Alternative\npotentials, spikes = network.step(inputs, membranePotential=True)\nThis method will return a list of membrane potentials for all neurons in the network after the current timestep has elapsed.\n\n\nUpdating Synapse Weights\nOnce the CRI_network class the topology of the network is fixed, that is what axon and neurons are in the network and how they are connected via synapses may not be changed. However it is possible to update the weight of preexisting synapses in the network. This can be done by calling the write_synapse() method of CRI_network. write_synapse() takes three arguments, the presynaptic neuron name, the postsynaptic neuron name, and the new synapse weight.\nnetwork.write_synapse('a', 'b', 2)"
  },
  {
    "objectID": "menu/tutorials/mnist.html",
    "href": "menu/tutorials/mnist.html",
    "title": "MNIST",
    "section": "",
    "text": "This tutorial goes over how to train a simple feedforward SNN and deploy on HiAER Spike using our conversion pipline.\n\n\nTo build a simple feedforward spiking neural network with PyTorch, we can use snnTorch, SpikingJelly or other deep learning frameworks that are based on PyTorch. Currently, our conversion pipline supports snnTorch and SpikingJelly. In this tutorial, we will be using SpikingJelly.\n$ pip install spikingjelly\nImport necessary libraries from SpikingJelly and PyTorch\nfrom spikingjelly.activation_based import neuron, functional \nimport torch \nimport torch.nn as nn\nUsing SpikingJelly, we can define a simple 2-layer feedforward SNN model with 1000 hidden neurons. The PyTorch layer will act as synapses between the spiking neuron layers.\nclass model(nn.Module):\n    def __init__(self, features = 1000):\n        super().__init__()\n        self.linear1 = nn.Linear(28 * 28, features, bias=False)\n        self.lif1 = neuron.LIFNode()\n        self.linear2 = nn.Linear(features, 10, bias=False)\n        self.lif2 = neuron.LIFNode()\n    \n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.lif1(x)\n        x = self.linear2(x)\n        x = self.lif2(x)\n        return x\nInitiate the Network\nnet = model()"
  },
  {
    "objectID": "menu/tutorials/mnist.html#feedforward-fully-connected-snn",
    "href": "menu/tutorials/mnist.html#feedforward-fully-connected-snn",
    "title": "MNIST",
    "section": "",
    "text": "This tutorial goes over how to train a simple feedforward SNN and deploy on HiAER Spike using our conversion pipline.\n\n\nTo build a simple feedforward spiking neural network with PyTorch, we can use snnTorch, SpikingJelly or other deep learning frameworks that are based on PyTorch. Currently, our conversion pipline supports snnTorch and SpikingJelly. In this tutorial, we will be using SpikingJelly.\n$ pip install spikingjelly\nImport necessary libraries from SpikingJelly and PyTorch\nfrom spikingjelly.activation_based import neuron, functional \nimport torch \nimport torch.nn as nn\nUsing SpikingJelly, we can define a simple 2-layer feedforward SNN model with 1000 hidden neurons. The PyTorch layer will act as synapses between the spiking neuron layers.\nclass model(nn.Module):\n    def __init__(self, features = 1000):\n        super().__init__()\n        self.linear1 = nn.Linear(28 * 28, features, bias=False)\n        self.lif1 = neuron.LIFNode()\n        self.linear2 = nn.Linear(features, 10, bias=False)\n        self.lif2 = neuron.LIFNode()\n    \n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.lif1(x)\n        x = self.linear2(x)\n        x = self.lif2(x)\n        return x\nInitiate the Network\nnet = model()"
  },
  {
    "objectID": "menu/tutorials/mnist.html#setting-up-the-mnist-dataset",
    "href": "menu/tutorials/mnist.html#setting-up-the-mnist-dataset",
    "title": "MNIST",
    "section": "Setting up the MNIST dataset",
    "text": "Setting up the MNIST dataset\nfrom torchvision import datasets, transforms\n\n# Download MNIST data from torch \nmnist_train = datasets.MNIST(\n    'data/mnist',\n    train=True,\n    download=True, \n    transform=transforms.Compose([transforms.ToTensor()])\n)\n\nmnist_test = datasets.MNIST(\n    'data/mnist',\n    train=False,\n    download=True,\n    transform=transforms.Compose([transforms.ToTensor()])\n)\n\n# Create DataLoaders\ntrain_loader = DataLoader(mnist_train, batch_size=128, shuffle=True, drop_last=True)\ntest_loader = DataLoader(mnist_test, batch_size=128, shuffle=True, drop_last=True)"
  },
  {
    "objectID": "menu/tutorials/mnist.html#training-the-snn",
    "href": "menu/tutorials/mnist.html#training-the-snn",
    "title": "MNIST",
    "section": "Training the SNN",
    "text": "Training the SNN\nSince we are using a static image dataset, we have to encode the image into spikes using the encoding function from spikingjelly.\n# Setting up the encoder\nencoder = encoding.PoissonEncoder\n#Using Adam optimizer with a learning rate of 0.1\noptimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n\n# Define training parameters\nepochs = 10\n\nfor epoch in range(epochs):\n        start_time = time.time()\n        net.train()\n        train_loss = 0\n        train_acc = 0\n        train_samples = 0\n        for img, label in train_loader:\n            optimizer.zero_grad()\n            img = img.to(device)\n            label = label.to(device)\n            label_onehot = F.one_hot(label, 10).float()\n            for t in range(args.num_steps):\n                encoded_img = encoder(img)\n                out_fr += net(encoded_img)\n            out_fr = out_fr/args.num_steps  \n            loss = loss_fun(out_fr, label_onehot)\n            loss.backward()\n            optimizer.step()\n\n            train_samples += label.numel()\n            train_loss += loss.item() * label.numel()\n            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n\n            functional.reset_net(net)\n\n        train_time = time.time()\n        train_speed = train_samples / (train_time - start_time)\n        train_loss /= train_samples\n        train_acc /= train_samples"
  },
  {
    "objectID": "menu/tutorials/mnist.html#converting-the-snn-to-hiaer-spike-format",
    "href": "menu/tutorials/mnist.html#converting-the-snn-to-hiaer-spike-format",
    "title": "MNIST",
    "section": "Converting the SNN to HiAER Spike Format",
    "text": "Converting the SNN to HiAER Spike Format\nfrom converter import *\nfrom l2s.api import CRI_network\n\n#Fold the BN layer \nbn = BN_Folder() \nnet_bn = bn.fold(net)\n\n#Weight, Bias Quantization \nqn = Quantize_Network() \nnet_quan = qn.quantize(net_bn)\n\n#Convert to HiAER-Spike Dictionaries\nnum_steps = 4\ninput_layer = 0\noutput_layer = 11\ninput_size = (3, 32, 32)\nbackend = 'snnTorch'\nthreshold = qn.v_threshold\n\ncn = CRI_Converter(num_steps = num_steps, \n                   input_layer = input_layer, \n                   output_layer = output_layer, \n                   input_shape = input_shape,\n                   backend=backend,\n                   v_threshold = v_threshold)\ncn.layer_converter(net_quan)"
  },
  {
    "objectID": "menu/tutorials/mnist.html#initialize-the-hiaer-spike-snn",
    "href": "menu/tutorials/mnist.html#initialize-the-hiaer-spike-snn",
    "title": "MNIST",
    "section": "Initialize the HiAER Spike SNN",
    "text": "Initialize the HiAER Spike SNN\nconfig = {}\nconfig['neuron_type'] = \"I&F\"\nconfig['global_neuron_params'] = {}\nconfig['global_neuron_params']['v_thr'] = int(quan_fun.v_threshold)\n    \n\nhardwareNetwork = CRI_network(dict(cri_convert.axon_dict),\n                              connections=dict(cri_convert.neuron_dict),\n                              config=config,target='CRI', \n                              outputs = cri_convert.output_neurons,\n                              coreID=1)\n\nsoftwareNetwork = CRI_network(dict(cri_convert.axon_dict),\n                              connections=dict(cri_convert.neuron_dict),\n                              config=config,target='simpleSim', \n                              outputs = cri_convert.output_neurons,\n                              coreID=1)"
  },
  {
    "objectID": "menu/tutorials/mnist.html#deploying-the-snn-on-hiaer-spike",
    "href": "menu/tutorials/mnist.html#deploying-the-snn-on-hiaer-spike",
    "title": "MNIST",
    "section": "Deploying the SNN on HiAER Spike",
    "text": "Deploying the SNN on HiAER Spike\ncri_convert.bias_start_idx = int(cri_convert.output_neurons[0])\nloss_fun = nn.MSELoss()\nstart_time = time.time()\ntest_loss = 0\ntest_acc = 0\ntest_samples = 0\nnum_batches = 0\nfor img, label in tqdm(test_loader):\n    cri_input = cri_convert.input_converter(img)\n    output = torch.tensor(cri_convert.run_CRI_hw(cri_input,hardwareNetwork), dtype=float)\n    loss = loss_fun(output, label)\n    test_samples += label.numel()\n    test_loss += loss.item() * label.numel()\n    test_acc += (output == label).float().sum().item()\n    num_batches += 1\ntest_time = time.time()\ntest_speed = test_samples / (test_time - start_time)\ntest_loss /= test_samples\ntest_acc /= test_samples\n\nprint(f'test_loss ={test_loss: .4f}, test_acc ={test_acc: .4f}')\nprint(f'test speed ={test_speed: .4f} images/s')"
  }
]